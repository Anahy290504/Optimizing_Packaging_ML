{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9bd0af1e-cc58-4a44-a661-3de2ac6a9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data (ensure to replace the path securely or use environment variables)\n",
    "#data = pd.read_csv(r'C:\\Users\\jpscw\\Documents\\EDA Anahy\\full_data_best_secret.csv')\n",
    "\n",
    "# Prompt the user to input the file path for the CSV file\n",
    "#file_path = input(\"Please enter the path to the CSV file: \")\n",
    "\n",
    "# Step 2: Load the CSV into a DataFrame\n",
    "#try:\n",
    "   # data = pd.read_csv(file_path)\n",
    "   # print(\"CSV file loaded successfully.\")\n",
    "#except Exception as e:\n",
    "   # print(f\"Error loading CSV file: {e}\")\n",
    "   # exit()  # Exit if the file cannot be loaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce0fea-02ac-47c3-90d4-de3729c72215",
   "metadata": {},
   "source": [
    "Filter rows where qty_items_sold == 1, then group by order_code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "662b9ad2-2eb4-426e-8bc9-8b0ee5dcc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to keep only rows where qty_items_sold == 1\n",
    "df_filtered = data[data['qty_items_sold'] == 1]\n",
    "\n",
    "# Group by 'order_code' and filter out groups with more than 1 row (i.e., keep single-item orders)\n",
    "df_single = df_filtered.groupby('order_code').filter(lambda x: len(x) == 1)\n",
    "\n",
    "# Count total products for each category (using value_counts)\n",
    "total_counts = df_single['product_navision_detail_category'].value_counts().reset_index()\n",
    "total_counts.columns = ['product_navision_detail_category', 'total_count']\n",
    "\n",
    "# Count occurrences of each box type for each category\n",
    "box_counts = df_single.groupby(['product_navision_detail_category', 'display_name']).size().reset_index(name='count')\n",
    "\n",
    "# Merge counts to calculate percentages\n",
    "merged = pd.merge(box_counts, total_counts, on='product_navision_detail_category')\n",
    "merged['percentage'] = (merged['count'] / merged['total_count']) * 100\n",
    "\n",
    "# Pivot the results to get the percentage table for box types across categories\n",
    "box_distribution_percentage = merged.pivot_table(\n",
    "    index='product_navision_detail_category',\n",
    "    columns='display_name',\n",
    "    values='percentage',\n",
    "    fill_value=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7888a-fb1a-4890-af7a-ca45ad4d20ac",
   "metadata": {},
   "source": [
    "Identify categories with any box type used more than 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "970685ba-aa27-4de8-9014-5c36aca032f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for categories with a box type used > 90%\n",
    "categories_with_high_usage = merged[merged['percentage'] >= 90]\n",
    "\n",
    "# Get the unique categories that meet the condition\n",
    "unique_categories = categories_with_high_usage['product_navision_detail_category'].unique()\n",
    "\n",
    "# Count unique categories with box usage > 90%\n",
    "number_unique_categories = len(unique_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e3969-ec0b-49e0-b51a-828261225340",
   "metadata": {},
   "source": [
    "We create a function to calculate the volume of each box type and return a sorted table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66d8629d-76ae-4d43-afdc-cba9a2c770e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_box_volumes(df):\n",
    "    df['width_in_millimeter'] = pd.to_numeric(df['width_in_millimeter'], errors='coerce')\n",
    "    df['length_in_millimeter'] = pd.to_numeric(df['length_in_millimeter'], errors='coerce')\n",
    "    df['height_in_millimeter'] = pd.to_numeric(df['height_in_millimeter'], errors='coerce')\n",
    "\n",
    "    # Calculate the volume for each row\n",
    "    df['volume_in_cubic_mm'] = df['width_in_millimeter'] * df['length_in_millimeter'] * df['height_in_millimeter']\n",
    "    \n",
    "    # Group by 'display_name' and calculate average volume for each box type\n",
    "    box_volumes = df.groupby('display_name')['volume_in_cubic_mm'].mean().reset_index()\n",
    "    \n",
    "    # convert from cubic millimeters to cubic centimeters for more intuitive results\n",
    "    box_volumes['volume_in_cubic_cm'] = box_volumes['volume_in_cubic_mm'] / 1000  # 1 cm³ = 1000 mm³\n",
    "\n",
    "    # Sort the results for easier interpretation\n",
    "    box_volumes_sorted = box_volumes.sort_values(by='volume_in_cubic_cm', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return box_volumes_sorted\n",
    "\n",
    "# Usage\n",
    "box_volumes_single = calculate_box_volumes(df_single)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc97ec-7a79-4744-b06f-d79c7976fd3e",
   "metadata": {},
   "source": [
    "We will identify the most used box types for each category and merge their volumes with the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af2a9c1b-cbf2-468d-a5b7-1a65e153f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the most used box for each category\n",
    "most_used_boxes = box_distribution_percentage.idxmax(axis=1)\n",
    "most_used_percentages = box_distribution_percentage.max(axis=1)\n",
    "\n",
    "# Create a DataFrame for the categories with box usage > 90%\n",
    "high_usage_categories = most_used_boxes[most_used_percentages >= 90].reset_index()\n",
    "high_usage_categories.columns = ['product_navision_detail_category', 'most_used_box']\n",
    "\n",
    "# Merge to get the volume of the most used box\n",
    "high_usage_categories = pd.merge(\n",
    "    high_usage_categories,\n",
    "    box_volumes_single[['display_name', 'volume_in_cubic_cm']],\n",
    "    left_on='most_used_box',\n",
    "    right_on='display_name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Keep only the relevant columns\n",
    "high_usage_categories = high_usage_categories[['product_navision_detail_category', 'volume_in_cubic_cm']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d1d39-762c-4765-8ff2-26f2a630407a",
   "metadata": {},
   "source": [
    "Now we apply a function to calculate weighted volumes based on usage percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58089496-a36a-47e9-a73f-d4c610dc67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_volume(row, box_volumes):\n",
    "    used_boxes = row[row > 0]  # Select boxes with non-zero usage\n",
    "    box_names = used_boxes.index.tolist()  # List of box types used for this category\n",
    "\n",
    "    # Get corresponding volumes for these boxes\n",
    "    used_box_volumes = box_volumes[box_volumes['display_name'].isin(box_names)]\n",
    "    \n",
    "    weighted_sum = 0\n",
    "    for box in used_box_volumes['display_name']:\n",
    "        percentage = row[box] / 100  # Convert percentage to decimal\n",
    "        volume = used_box_volumes[used_box_volumes['display_name'] == box]['volume_in_cubic_cm'].values[0]\n",
    "        weighted_sum += percentage * volume\n",
    "    \n",
    "    num_boxes_used = len(used_boxes)\n",
    "    weighted_volume = weighted_sum / num_boxes_used if num_boxes_used > 0 else 0\n",
    "    return weighted_volume\n",
    "\n",
    "# Calculate the weighted volume for each category\n",
    "box_volumes_mapping = box_volumes_single[['display_name', 'volume_in_cubic_cm']]\n",
    "box_distribution_percentage['weighted_volume'] = box_distribution_percentage.apply(calculate_weighted_volume, axis=1, box_volumes=box_volumes_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fa716dd-259a-4fa7-883c-f8647dd3410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for high usage categories with the most used box volume\n",
    "high_usage_volume_dict = high_usage_categories.set_index('product_navision_detail_category')['volume_in_cubic_cm'].to_dict()\n",
    "\n",
    "# Create a dictionary for weighted volumes\n",
    "weighted_volume_dict = box_distribution_percentage['weighted_volume'].to_dict()\n",
    "\n",
    "# Define a function to assign the appropriate volume based on category\n",
    "def assign_approximated_volume(row):\n",
    "    category = row['product_navision_detail_category']\n",
    "    \n",
    "    if category in high_usage_volume_dict:\n",
    "        return high_usage_volume_dict[category]\n",
    "    elif category in weighted_volume_dict:\n",
    "        return weighted_volume_dict[category]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to create the 'approximated_volume' column in df_single\n",
    "df_single['approximated_volume'] = df_single.apply(assign_approximated_volume, axis=1)\n",
    "\n",
    "# Create a DataFrame with unique product categories and their approximated volumes\n",
    "df_single_unique = df_single[['product_navision_detail_category', 'approximated_volume']].drop_duplicates(subset='product_navision_detail_category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbc08a-97e1-4d22-a084-92236b58ff85",
   "metadata": {},
   "source": [
    "Now we get the approximated volumes for the rest of categories (that have no errors in the columns 'qty_items_sold', 'qty_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ffaad4c-408c-4734-9dd8-703178b18e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Clean the orders where 'qty_items_sold' doesn't match the 'qty_items'\n",
    "# Group by 'order_code' and sum 'qty_items_sold'\n",
    "df_qty_items_sold_sum = data.groupby('order_code')['qty_items_sold'].sum().reset_index()\n",
    "\n",
    "# Group by 'order_code' and take the first value of 'qty_items'\n",
    "df_qty_items_first = data.groupby('order_code')['qty_items'].first().reset_index()\n",
    "\n",
    "# Merge the two dataframes on 'order_code' for comparison\n",
    "df_comparison = pd.merge(df_qty_items_sold_sum, df_qty_items_first, on='order_code', suffixes=('_sold_sum', '_first'))\n",
    "\n",
    "# Create a new column 'are_same' to compare the two columns and filter mismatches\n",
    "df_comparison['are_same'] = df_comparison['qty_items_sold'] == df_comparison['qty_items']\n",
    "\n",
    "# Filter rows where the values are not the same\n",
    "df_not_same = df_comparison[df_comparison['are_same'] == False]\n",
    "\n",
    "# Extract order codes with mismatches\n",
    "order_codes_to_remove = df_not_same['order_code']\n",
    "\n",
    "# Remove rows from the original data where order codes have mismatches\n",
    "df_cleaned = data[~data['order_code'].isin(order_codes_to_remove)]\n",
    "\n",
    "# Step 2: Identify categories that are in 'df_cleaned' but not in 'df_single_unique'\n",
    "categories_df_single = set(df_single_unique['product_navision_detail_category'])\n",
    "categories_df_cleaned = set(df_cleaned['product_navision_detail_category'])\n",
    "\n",
    "# Find categories not in df_single\n",
    "categories_not_in_single = categories_df_cleaned - categories_df_single\n",
    "filtered_data = df_cleaned[df_cleaned['product_navision_detail_category'].isin(categories_not_in_single)]\n",
    "\n",
    "# Step 3: Process orders with only one unique category from the excluded ones\n",
    "orders_with_single_excluded_category = filtered_data.groupby('order_code').filter(\n",
    "    lambda x: x['product_navision_detail_category'].nunique() == 1\n",
    ")\n",
    "\n",
    "# Count the occurrences of each category in the filtered orders\n",
    "category_counts = orders_with_single_excluded_category['product_navision_detail_category'].value_counts()\n",
    "\n",
    "# Step 4: Create a dictionary for each order_code with associated categories\n",
    "grouped_categories = filtered_data.groupby('order_code')['product_navision_detail_category'].agg(list)\n",
    "categories_dict = grouped_categories.to_dict()\n",
    "\n",
    "# Step 5: Calculate maximum volume for excluded categories\n",
    "max_volume_results = {}\n",
    "\n",
    "\"\"\"\n",
    "This function iterates over each order and calculates the approximate volume of products\n",
    "that belong to excluded categories (categories not present in df_single_unique). It works by:\n",
    "1. Determining the box volume used for each order.\n",
    "2. Calculating the total adjusted volume for included categories based on the quantity of items sold.\n",
    "3. Estimating the remaining volume in the box for excluded categories.\n",
    "4. Tracking the maximum estimated volume for each excluded category across all orders.\n",
    "The results are stored in the `max_volume_results` dictionary.\n",
    "\"\"\"\n",
    "\n",
    "# Iterate over each order code and its associated categories\n",
    "for order_code, categories in categories_dict.items():\n",
    "    # Retrieve box volume used for the order\n",
    "    box_used = data[data['order_code'] == order_code]['display_name'].unique()\n",
    "\n",
    "    if len(box_used) == 0:\n",
    "        continue  # Skip if no box information is found\n",
    "\n",
    "    box_display_name = box_used[0]\n",
    "\n",
    "    # Retrieve the box volume\n",
    "    box_volume_row = box_volumes_single[box_volumes_single['display_name'] == box_display_name]\n",
    "\n",
    "    if box_volume_row.empty:\n",
    "        continue  # Skip if no box volume is found\n",
    "\n",
    "    box_volume_cm3 = box_volume_row['volume_in_cubic_cm'].values[0]\n",
    "\n",
    "    # Filter out the categories that are in df_single_unique and calculate adjusted volumes\n",
    "    approximated_volumes = df_single_unique[df_single_unique['product_navision_detail_category'].isin(categories)]\n",
    "    \n",
    "    # Merge with qty_items_sold to calculate adjusted volume\n",
    "    merged_data = pd.merge(approximated_volumes, \n",
    "                           data[data['order_code'] == order_code][['product_navision_detail_category', 'qty_items_sold']],\n",
    "                           on='product_navision_detail_category', \n",
    "                           how='left')\n",
    "\n",
    "    merged_data['adjusted_volume'] = merged_data['approximated_volume'] * merged_data['qty_items_sold']\n",
    "    total_approximated_volume = merged_data['adjusted_volume'].sum()\n",
    "\n",
    "    # Calculate approximate volume for excluded category\n",
    "    approximate_volume_excluded_category = box_volume_cm3 - total_approximated_volume\n",
    "\n",
    "    # Track the maximum volume for the excluded category\n",
    "    excluded_categories = set(categories) - set(df_single_unique['product_navision_detail_category'])\n",
    "\n",
    "    if excluded_categories:\n",
    "        excluded_category = excluded_categories.pop()\n",
    "\n",
    "        if excluded_category in max_volume_results:\n",
    "            max_volume_results[excluded_category] = max(max_volume_results[excluded_category], approximate_volume_excluded_category)\n",
    "        else:\n",
    "            max_volume_results[excluded_category] = approximate_volume_excluded_category\n",
    "\n",
    "# Step 6: Convert the results to DataFrame\n",
    "results_df = pd.DataFrame(list(max_volume_results.items()), columns=['category', 'approximate_volume'])\n",
    "\n",
    "# Step 7: Merge results with the unique category volumes\n",
    "results_df = results_df.rename(columns={'category': 'product_navision_detail_category', 'approximate_volume': 'approximated_volume'})\n",
    "\n",
    "# Combine with existing approximated volumes DataFrame\n",
    "combined_df_final = pd.concat([df_single_unique, results_df], ignore_index=True)\n",
    "\n",
    "# Filter out entries with negative or zero volumes\n",
    "combined_df_final = combined_df_final[combined_df_final['approximated_volume'] > 0]\n",
    "\n",
    "# Step 4: Create the final dictionary of volumes\n",
    "final_volume_dict = combined_df_final.set_index('product_navision_detail_category')['approximated_volume'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "848337e6-8931-4049-bdb0-8187258dc1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###IN CASE YOU PREFER TO WRITE WITH A JSON FILE\n",
    "#import json\n",
    "#with open('volume_dict.json', 'w') as f:\n",
    "    #json.dump(final_volume_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "985796b7-33ee-4fe2-8722-47225e2aebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dictionary to a .py file with UTF-8 encoding\n",
    "with open('volume_dict.py', 'w', encoding='utf-8') as f:\n",
    "    f.write('volume_dict = ' + str(final_volume_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
